{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pprint as pprn\n",
    "from typing import Callable\n",
    "from collections import OrderedDict\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset: pd.DataFrame, dropna_rows_naive: bool, columns_to_drop: list):\n",
    "    if dropna_rows_naive:\n",
    "        dataset.dropna(axis=0, inplace=True)\n",
    "\n",
    "    if isinstance(columns_to_drop, list) and columns_to_drop:\n",
    "        dataset.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def transform_dataset_column(dataset: pd.DataFrame, column_name: str, transform_function: Callable):\n",
    "    dataset[column_name] = dataset[column_name].apply(transform_function)\n",
    "\n",
    "\n",
    "def prepare_train_and_test_data(dataset_train: pd.DataFrame, dataset_test: pd.DataFrame, target_variable_name: str):\n",
    "    X_train = dataset_train.drop(target_variable_name, axis=1)\n",
    "    Y_train = dataset_train[target_variable_name]\n",
    "\n",
    "    X_test = dataset_test.drop(target_variable_name, axis=1)\n",
    "    Y_test = dataset_test[target_variable_name]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "class LogRegressionModel(enum.Enum):\n",
    "    EQUAL_WEIGHTS = 1,\n",
    "    AUTO_BALANCED_WEIGHTS = 2,\n",
    "    MANUAL_BALANCED_WEIGHTS = 3\n",
    "\n",
    "\n",
    "def train_logistic_regression(X_train: pd.DataFrame, Y_train,\n",
    "                              model_type: LogRegressionModel = LogRegressionModel.EQUAL_WEIGHTS,\n",
    "                              class_weights: list = None) -> linear_model.LogisticRegression:\n",
    "    if LogRegressionModel.EQUAL_WEIGHTS == model_type:\n",
    "        model = linear_model.LogisticRegression(\n",
    "            solver='liblinear', class_weight=None)\n",
    "    elif LogRegressionModel.AUTO_BALANCED_WEIGHTS == model_type:\n",
    "        model = linear_model.LogisticRegression(\n",
    "            solver='liblinear', class_weight='balanced')\n",
    "    elif LogRegressionModel.MANUAL_BALANCED_WEIGHTS == model_type:\n",
    "        model = linear_model.LogisticRegression(solver='liblinear', class_weight={\n",
    "                                                0: class_weights[0], 1: class_weights[1]})\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_with_logistic_regression(model: linear_model.LogisticRegression, X_test: pd.DataFrame):\n",
    "    return model.predict(X_test)\n",
    "\n",
    "\n",
    "def calculate_model_scores(X_test: pd.DataFrame, Y_test, Y_predicted,\n",
    "                           model: sklearn.base.ClassifierMixin = None, print_scores: bool = False) -> dict:\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, Y_predicted)\n",
    "\n",
    "    TN = confusion_matrix[0, 0]  # True Negative\n",
    "    TP = confusion_matrix[1, 1]  # True Positive\n",
    "    FN = confusion_matrix[1, 0]  # False Negative\n",
    "    FP = confusion_matrix[0, 1]  # False Positive\n",
    "\n",
    "    scores = OrderedDict()\n",
    "\n",
    "    if model:\n",
    "        scores[\"accuracy_model\"] = model.score(X_test, Y_test)\n",
    "    scores[\"accuracy\"] = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    scores[\"sensitivity\"] = TP / (TP + FN)\n",
    "    scores[\"specificity\"] = TN / (TN + FP)\n",
    "\n",
    "    scores[\"precision\"] = TP / (TP + FP)\n",
    "\n",
    "    scores[\"error_typeI\"] = FP / (FP + TN)\n",
    "    scores[\"error_typeII\"] = FN / (FN + TP)\n",
    "\n",
    "    if print_scores:\n",
    "        print(\"[Model Scores]\")\n",
    "        pprn.pprint(scores)\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Admission_train.csv')\n",
    "df_test = pd.read_csv('Admission_test.csv')\n",
    "\n",
    "prepare_dataset(df_train, dropna_rows_naive=True,\n",
    "                columns_to_drop=[\"Unnamed: 0\", \"Serial No.\"])\n",
    "prepare_dataset(df_test, dropna_rows_naive=True,\n",
    "                columns_to_drop=[\"Unnamed: 0\", \"Serial No.\"])\n",
    "\n",
    "target_variable_name = \"Chance of Admit\"\n",
    "transform_dataset_column(df_train, target_variable_name,\n",
    "                         lambda value: 0 if value < 0.5 else 1)\n",
    "transform_dataset_column(df_test, target_variable_name,\n",
    "                         lambda value: 0 if value < 0.5 else 1)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = prepare_train_and_test_data(\n",
    "    df_train, df_test, target_variable_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Scores]\n",
      "OrderedDict([('accuracy_model', 0.91),\n",
      "             ('accuracy', 0.91),\n",
      "             ('sensitivity', 0.967032967032967),\n",
      "             ('specificity', 0.3333333333333333),\n",
      "             ('precision', 0.9361702127659575),\n",
      "             ('error_typeI', 0.6666666666666666),\n",
      "             ('error_typeII', 0.03296703296703297)])\n"
     ]
    }
   ],
   "source": [
    "model = train_logistic_regression(\n",
    "    X_train, Y_train, LogRegressionModel.EQUAL_WEIGHTS)\n",
    "Y_predicted = predict_with_logistic_regression(model, X_test)\n",
    "model_scores = calculate_model_scores(\n",
    "    X_test, Y_test, Y_predicted, model=model, print_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Scores]\n",
      "OrderedDict([('accuracy_model', 0.78),\n",
      "             ('accuracy', 0.78),\n",
      "             ('sensitivity', 0.7802197802197802),\n",
      "             ('specificity', 0.7777777777777778),\n",
      "             ('precision', 0.9726027397260274),\n",
      "             ('error_typeI', 0.2222222222222222),\n",
      "             ('error_typeII', 0.21978021978021978)])\n"
     ]
    }
   ],
   "source": [
    "model = train_logistic_regression(\n",
    "    X_train, Y_train, LogRegressionModel.AUTO_BALANCED_WEIGHTS)\n",
    "Y_predicted = predict_with_logistic_regression(model, X_test)\n",
    "model_scores = calculate_model_scores(\n",
    "    X_test, Y_test, Y_predicted, model=model, print_scores=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "510017f941ecd040108aa6155b7d7920a30c358be25c6738528295864459697b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
